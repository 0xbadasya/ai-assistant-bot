import { Injectable } from '@nestjs/common';
import OpenAI from 'openai';
import { PrismaService } from '../prisma/prisma.service';

function extractJson(text: string): string {
  const jsonStart = text.indexOf('{');
  const jsonEnd = text.lastIndexOf('}');
  if (jsonStart !== -1 && jsonEnd !== -1 && jsonEnd > jsonStart) {
    return text.slice(jsonStart, jsonEnd + 1);
  }
  return '{}';
}

@Injectable()
export class AiService {
  private readonly openai: OpenAI;

  constructor(private readonly prisma: PrismaService) {
    this.openai = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });
  }

  async generateReply(prompt: string, userId: string): Promise<string> {
    try {
      const chatCompletion = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: `–¢–∏ –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–∏–π –∞—Å–∏—Å—Ç–µ–Ω—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞. –ó–∞–≤–∂–¥–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π —Ç–µ–ø–ª–æ, —Å—Ç–∏—Å–ª–æ, –∑ –µ–º–æ–¥–∑—ñ, –Ω—ñ–±–∏ —Ç–∏ –¥—Ä—É–≥.`,
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        user: userId, 
      });

      const reply = chatCompletion.choices[0]?.message?.content ?? 'ü§ñ GPT –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–≤.';

      await this.prisma.sessionLog.create({
        data: {
          userId: userId, 
          prompt,
          response: reply,
          type: 'message',
        },
      });

      return reply;
    } catch (error: any) {
      const fallback = error.status === 429
        ? 'üö´ –í–∏—á–µ—Ä–ø–∞–Ω–æ –ª—ñ–º—ñ—Ç OpenAI.'
        : '‚ùå –°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ.';

      await this.prisma.sessionLog.create({
        data: {
          userId: userId, 
          prompt,
          response: fallback,
          type: 'error',
          meta: {
            message: error.message,
            code: error.code || null,
            status: error.status || null,
          },
        },
      });

      return fallback;
    }
  }

  // –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–¥–∞—á—ñ –∑ —Ç–µ–∫—Å—Ç—É
  async parseTask(text: string): Promise<{ title: string; description?: string; date: string } | null> {
    try {
      const result = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content:
              '–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Ä–æ–∑—ñ–±—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —ñ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –∑–∞–¥–∞—á—É. –ü–æ–≤–µ—Ä–Ω–∏ JSON —É —Ñ–æ—Ä–º–∞—Ç—ñ: { "title": "...", "description": "...", "date": "ISO string" }.',
          },
          { role: 'user', content: text },
        ],
        temperature: 0.2,
      });

      const raw = result.choices[0]?.message?.content || '{}';
      const cleaned = extractJson(raw);
      return JSON.parse(cleaned);
    } catch (error: any) {
      if (error.status === 429 || error.code === 'insufficient_quota') {
        console.warn('‚ùó –í–∏—á–µ—Ä–ø–∞–Ω–æ –ª—ñ–º—ñ—Ç OpenAI –≤ parseTask');
      } else {
        console.error('‚ùå parseTask GPT error:', error);
      }
      return null;
    }
  }

  // –ü–∞—Ä—Å–∏–Ω–≥ –ø–æ–¥—ñ—ó –¥–ª—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è
  async parseCalendarEvent(text: string): Promise<{ summary: string; start: string; end: string } | null> {
    const result = await this.openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content:
            '–¢–∏ –ø–∞—Ä—Å–∏—à —Ç–µ–∫—Å—Ç –ø–æ–¥—ñ—ó –¥–ª—è –∫–∞–ª–µ–Ω–¥–∞—Ä—è. –ü–æ–≤–µ—Ä–Ω–∏ JSON —É —Ñ–æ—Ä–º–∞—Ç—ñ: { "summary": "...", "start": "ISO", "end": "ISO" }. –î–∞—Ç–∏ –º–∞—é—Ç—å –±—É—Ç–∏ —á—ñ—Ç–∫–∏–º–∏!',
        },
        { role: 'user', content: text },
      ],
      temperature: 0.2,
    });

    try {
      const raw = result.choices[0]?.message?.content || '{}';
      const cleaned = extractJson(raw);
      return JSON.parse(cleaned);
    } catch (error) {
      console.warn('‚ùå GPT parseCalendarEvent error:', error);
      return null;
    }
  }
}
